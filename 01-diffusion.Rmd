# Flow Matching and Diffusion {#flowDiffusion}

This section explores flow matching and diffusion models based on the [MIT lecture series](https://diffusion.csail.mit.edu/). Also see lecture notes [@holderrieth2025introduction] and [materials](#https://diffusion.csail.mit.edu/#lectures). More advanced, supplemental proofs are referenced from [@li2025unified]. 

1. Flow models parameterize the **vector field** (in the same space as data, for Euclidean data) which induces a specified probability path. Diffusion models generalize by adding Brownian noise, PDE $\to$ SDE. 
2. Crucial bridge between vector field and probability path: continuity equation \@ref(thm:contEq)  resp. \@ref(thm:fokkerPlanck) Fokker-Planck in SDE case. 
    - Given the probabaility velocity vector field $u_t$ and $\Pinit$, we can directly compute $\pd t p_t$ via the Fokker-Planck equation. 
    Conversely, given $p_t$, we can always construct (non-unique) vector field which matches the probability path. 
3. Conditioning on a single data point $z$ with dirac delta target $\delta_z$, the conditional vector field has simple analytic solution. Apply the marginalization trick \@ref(thm:margTrick) to generalize to whole empirical data distribution. 
    - <u>Very important remark</u>: fixing $\Pinit$, the mapping $u_t\mapsto p_t$ **is not linear**. The vector field $u_t$ specifies the **probability velocity**, while mixture linearly superimposes the **probability flux** $u_tp_t$.
4. The marginal vector field \@ref(thm:margTrick) and score generally have intractable integrals, but crucially, optimizing MSE to the conditional v. marginal distribution have the same desired behavior (theorem \@ref(thm:opEq)). 
5. <span style="blue"> Crux of using deep modeling </span>: having solved the simple conditional case analytically, we're relying on the model to: 
    - Model marginal quantities by optimization equivalence, without resorting to intractable integrals **(very smart theme!!)**
    - Generalize / interpolate the vector field to assign mass to unseen regions of the data manifold. 
6. Under the [Gaussian probability path](@gaussian), the network essentially learns to predict the noise which is used to corrupt data; conversion between score vs target network targets \@ref(prp:gaussianFormulae). 

## Modeling {#prelim -}

- We presume an underlying, generally unknown, data distribution $\Pdata$ supported on $\R^d$.
- Dataset consists of finite samples $\{z_1, \dots, z_N\}\sim \Pdata$, effectively yielding an empirical distribution $\hat \Pdata$. 
- Unconditional generation consists of (1) estimating $\Pdata$ from $\hat \Pdata$, then drawing samples from the estimate. 
- Assuming a joint distribution with some conditioning variable $y\sim p_y$, conditional distribution consists of sampling from the conditional distribution $p(\cdot \mid y)$. 

In flow models, we model the data via a **mapping** $u:\R^d\to \R^d$ between standard Gaussian initial distribution  $\Pinit=\mca N(0, I_d)$ and the data distribution. This mapping is modeled as a <span style="color:blue">flow whose time-derivative is parameterized by a deep model</span>. Given a vector field 
\[ 
    (X_t, t)\mapsto u_t(X_t) \quad \text{of type}\quad u_{(\cdot)}(\cdot): \R^d\times \R \to \R^d
\] 
Treating the vector field $u_t$ as an integrable operator, the flow $\Phi_t: \R^d\to \R^d$ is obtained by integrating the vector field from $0$ to time $t$: 
\[ 
    \Phi_t(x_0) = \exp \left[\int_0^t u_\tau\, d\tau\right]x_0 \, \iff \pd t \Phi_t(x_0) = u_t\left[\Phi_t(x_0)\right] 
\] 
Such model above have deterministic dynamics, i.e. once $x_0\sim \Pinit$ is fixed, the sample is fixed. We may instead consider stochastic dynamics: 
\[ 
    dX_t = u_t(X_t)\, dt + \sigma_t\, dW_t \iff \Phi_t(x_0) = \exp \left[
       \int_0^t u_\tau \, d\tau + \int_0^t \sigma_\tau \, dW_\tau 
    \right] x_0 
\] 
where $W_t$ is the standard Brownian motion. This concludes our specification of generation procedure as a function of model parameters $\theta$ and $\sigma_t$. To generate a new data sample from our model: 

1. Sample $\epsilon\sim \Pinit$. 
2. Compute $x_1 = \Phi_1(x_0=\epsilon) = \exp \left[
       \int_0^1 u_\tau \, d\tau + \int_0^1 \sigma^t_\tau \, dW_\tau 
    \right] \epsilon$ using SDE approximation methods. 

## Vector fields and distributions {#vecFieldsAndDistributions -}

The next order of business is to train $\theta$ so that $x_1=\Phi_1(\Pinit)\approx \Pdata$. The main idea is to integrate tractable conditional solutions to obtain the full, marginalized solution. 
Given a (continuous) probability path $p_{(\cdot)}(\cdot): \R\to \Delta(\R^d)$, we can relate it to a vector field $u_{(\cdot)}:\R\times \R^d\to \R^d$ which realizes it as follows: 

:::{.theorem #contEq name="continuity equation"}
Under regularity conditions, define $x_0\sim \Pinit$ (note that $x_0$ is a random variable while $\Pinit$ is a distribution) and $x_t$ as the image of the flow 
\[ 
    x_t = \exp \left[
        \int_0^\tau u_\tau \, d\tau 
    \right]\, x_0\iff \pd t x_t = u_t(x_t) 
\] 
Let $p_t$ denote the induced distribution of $x_t$, then $\pd t \big|_\tau\, p_t = -\nabla \cdot (u_\tau \rho_\tau)$. The converse also holds, i.e. \pd t \big|_\tau\, p_t = -\nabla \cdot (u_\tau \rho_\tau)\implies \pd t x_t = u_t(x_t)$. 
:::
<details>
<summary>Use test function and reverse product rule, divergence theorem. The main idea is to write $\pd t \Exp_{p_t}[f]$ as $\Exp_{\pd t p_t}[f]$ as well as a $f$-integral. Expand the $f$-integral using chain rule and product rule, and apply divergence theorem to rid of one term</summary>
Consider arbitrary, time-invariant smooth test function $f$. First convince ourselves that we have 
\[ 
    \int f(x_t) p_0(x_0)\, dx_0 = \int f(x_t) p_t(x_t)\, dx_t 
\] 
To see this rigorously, let $x_t = \Phi_t(x_0)$, then by standard chain rule we have $dx_t = \det (D\Phi_t)\, dx_0$. On the other hand, by pushforward measure we have $p_t(\Phi_t(x_0)) = p_0(x_0) \det^{-1} (D\Phi_t)$. Proceeding: 
\begin{align}
    \pd t \Exp_{p_t} [f] 
    &= \pd t \int f(x_t) p_0(x_0)\, dx_0 = \pd t \int f\left[\exp \left(
        \int_0^t u_t\, d\tau 
    \right) x_0 \right] p_0(x_0)\, dx_0 \\ 
    &= \int \left[\nabla \big|_{x_t} f \right]\cdot u_t(x_t) \left[p_0(x_0)\, dx_0\right] 
    = \int \left[\nabla \big|_{x_t} f \right]\cdot \left[u_t(x_t) p_t(x_t)\right]\, dx_t \\ 
    &= \int \nabla \cdot (f u_t p_t)\big|_{x_t}  - f(x_t) \nabla\cdot (u_tp_t)\big|_{x_t} \, dx_t 
    = -\int f(x)\, \nabla \cdot (u_t p_t)\, dx 
\end{align} 
The first part vanishes since $p_t$ vanishes on far boundaries. 
On the other hand, we also have 
\begin{align}
    \pd t \Exp_{p_t} [f] 
    &= \pd t \int f(x) p_t(x)\, dx = \int f(x)\pd t p_t(x)\, dx 
\end{align}
Combining, we obtain $\pd t p_t = -\nabla \cdot (u_t p_t)$, as desired. 
</details>

Salient points: 

1. Given $u_t$, we can use it to compute $\pd t p_t$; given $p_0$, this gives us the rest of $p_t$. 
2. Given $\{p_t\}$, we can obtain a (non-unique) vector field which generates it by computing $\pd t p_t$ and fitting it to the divergence. This is always possible under regularity conditions because vector fields have more degrees of freedom. 

:::{.theorem #fokkerPlanck name="Fokker-Planck"}
Under regularity conditions, let $x_0\sim \Pinit$ and similarly define 
\[ 
    x_t = \exp \left[
        \int_0^t u_\tau \, d\tau + \int_0^t \sigma_\tau dW_\tau 
    \right]\, x_0 \iff dx_t = u_t(x_t)\, dt + \sigma_t\, dW_t 
\] 
Define $p_t$ such that $x_t\sim p_t$ and define the Lagrangian operator for scalar function $\nabla^2 p \equiv \nabla \cdot (\nabla p) = \tr(H_p)$. Then 
\[ 
    \forall x, \tau: \pd t \big|_\tau\, p_t = -\nabla \cdot (u_\tau \rho_\tau) + \df{\sigma_\tau^2}{2} \nabla^2 p_\tau
\] 
Again, note that $u_t$ is a vector field (differentiation operator) thus acts on scalar fields (or random variables) like $p_t$ by application (so we need to apply chain rule), while $\sigma_t$ is simply a scalar, thus acting by multiplication. 
:::
<details>
<summary>Use test function and reverse product rule, divergence theorem</summary>
To the first order, we obtain 
\[ 
    x_{t+h} \approx x_t + h\, u_t(x_t) + \sigma_t (W_{t+h} - W_t)
\] 
Here $u_t(x_t)$ is the tangent random variable denoting the application of $u_t$ to the crystallization of $x_t$. Given a scalar function $f$, we obtain 
\begin{aligned}
    f(x_{t+h}) - f(x_t) 
    &\approx (\nabla \big|_{x_t} f) \cdot \left[
        h\, u_t(x_t) + \sigma_t(W_{t+h} - W_t)\right] \\ 
    &\quad + \df 1 2 \left[
        h\, u_t(x_t) + \sigma_t(W_{t+h} - W_t)\right]^T \left(H_f \big|_{x_t}\right) \left[
        h\, u_t(x_t) + \sigma_t(W_{t+h} - W_t)\right] \\ 
    &= (\nabla f) \cdot \left[
        h\, u_t(x_t) + \sigma_t(W_{t+h} - W_t)\right] 
        + \df {h^2} 2 u_t(x_t)^T \, H_f \, u_t(x_t) \\ 
        &\quad + h \sigma_t \, u_t(x_t) H_f (W_{t+h} - W_t) 
        + \df {\sigma_t^2}{2} (W_{t+h} - W_t)^T H_f  (W_{t+h} - W_t)
\end{aligned}
Taking expectation, note that $\Exp[W_{t+h} - W_t]=0$ since $W_{t+h} - W_t\sim \mca N(0, \sigma^2=h)$. Also note that $\Exp[h^t Ah]=\Exp \tr(A hh^T)=\tr(A)$ for $h\sim \mca N(0, I_d)$, then 
\begin{aligned}
    \Exp[f(x_{t+h}) - f(x_t)]
    &=  \Exp \left[
    (\nabla f) \cdot u_t(x_t)\, h + \df{\sigma_t^2}{2} \tr(H_f) \, h + O(h^2)\right] \\ 
    \pd t \Exp[f(x_t)] &= \Exp\left[(\nabla f)\cdot u_t(x_t) + \df{\sigma_t^2}{2} \tr(H_f)\right]
\end{aligned}
Great! Next up, expand the integral and apply reverse product rule piece by piece. 
The first term is familiar from continuity equation \@ref(thm:contEq): 
\begin{aligned}
    \Exp[(\nabla f) \cdot u_t(x_t)]
    &= \int p_t(x) (\nabla_f) \cdot u_t(x)\, dx 
    = -\int f(x) \nabla \cdot (p_t u_t)\, dx 
\end{aligned}
By applying reverse product rule twice, the second term is seen to be 
\[ 
    \Exp[(\nabla f) \cdot u_t(x_t)]
    = \df{\sigma_t^2}{2} \int (\Delta \big|_x f) p_t(x)\, dx 
    = \df{\sigma_t^2}{2} \int f(x) \Delta p_t\, dx 
\] 
Combining, we have proved that for any regular scalar function $f$, we have 
\begin{aligned}
    \pd t \Exp[f(x_t)] = \int f(x) \left(\nabla \cdot (p_tu_t) + \df{\sigma^2}{2} \Delta p_t\right)\, dx = \int f(x) \pd t p_t(x)\, dx 
\end{aligned}
This shows that $\pd t p_t=\dots$ almost surely; the necessary direction follows from uniqueness of SDEs. 
</details>

:::{.remark name="Langevin dynamics"}
Fixing $\Pinit$ and set $\pd t p_t=0$ yields that the dynamics 
\[ 
    dx_t = \df{\sigma_t^2}{2} \nabla \log p(x_t)\, dt + \sigma_t\, dW_t 
\] 
has stationary distribution $\Pinit$. This is called **Langevin dynamics**. In fact, under mild regularity conditions this SDE pulls any initial law $p'$ to the fixed point. 
:::

## Marginalization {#marginalization -}

The following theorem is the main tool for converting conditional models into marginal ones. 

:::{.theorem #margTrick name="marginalization trick"}
Fixing $\Pdata$ and conditional probability paths $p_t(\cdot\mid z)$ interpolating between $\Pinit$ and $\delta_z$ (e.g. definition \@ref(def:condGaussianPath)). For each $z\in \R^d$ let $u^*_t(\cdot\mid z):\R^d\to \R^d$ denote a vector field which realizes the conditional probability path, i.e. 
\[ 
    \exp \left[
        \int_0^t
            u^*_\tau(\cdot\mid z)\, d\tau 
        \, d\tau 
    \right]\, (\epsilon \sim \Pinit) \sim p_t(\cdot \mid z) 
\] 
Then the marginal vector field defined as follows 
\[ 
    u_t(x) \equiv \int u_t^*(x\mid z) p_t(z\mid x)\, dz, \quad p_t(z\mid x) = \df{p_t(x\mid z) \Pdata(z)}{p_t(x)}
\] 
realizes the marginal probability distribution 
\[ 
    \exp \left[
        \int_0^t
            u^*_\tau\, d\tau 
    \right]\, (\epsilon \sim \Pinit) \sim p_t = \int p_t(\cdot\mid z)\, dz 
\] 
:::

Per continuity equation \@ref(thm:contEq), it suffices to check that the divergence of the proposed vector field matches the time-derivative of the marginal distribution $p_t$: 
\begin{aligned}
    -\nabla \cdot (u_t p_t) \big|_x 
    &= -\nabla \cdot \left[
        p_t(x) \int u_t^*(x\mid z) p_t(z\mid x)\, dz
    \right] \\ 
    &= -\int \nabla \cdot \left[u_t^*(x\mid z) p_t(x\mid z) \Pdata (z) \right]\, dz \\ 
    &= -\int \Pdata(z)\, \nabla \cdot \left[u_t^*(x\mid z) p_t(x\mid z)\right]\, dz \\ 
    &= \int \Pdata(z) \pd t p_t(x\mid z)\, dz = \pd t p_t(x)
\end{aligned}

Several important points:

1. Fixing $t$, we're working with the joint distribution over $z\sim \Pdata$ and $p_t(x_t\mid z)$. This underpins the simplification $p_t(x) p_t(z\mid x) = p_t(x\mid z) \Pdata(z)$. 
2. DIvergence is taken w.r.t. the $x$ variable! This is why $\Pdata(z)$ slides out of divergence as a constant. 
3. Proof sketch: compute the divergence by substituting ansatz for the marginal vector field $u_t$, apply continuity equation to conditional vector field to convert divergence to time-derivative, then marginalize. 

<details>
<summary><span style="color:blue"> IMPORTANT: why $u_t\neq \int u_t^*(\cdot \mid z) \Pdata(z)\, dz$</span></summary>
Zeroth-order intuition seems to suggest that "since everything is linear", let's just substitute $u_t(x) = \int u_t^*(x\mid z) \Pdata(z)\, dz$. However, invoking the same machinery yields: 
\begin{aligned}
    -\nabla \cdot (u_t p_t) \big|_x 
    &= -\nabla \cdot \left[
        p_t(x) \int u_t^*(x\mid z) \Pdata(z) \, dz
    \right] \\ 
    &= -\int \nabla \cdot \left[u_t^*(x\mid z) p_t(x\mid z) \df{p_t(x)\Pdata(z)}{p_t(x\mid z)} \right]\, dz
\end{aligned}
Importantly, we don't obtain the clean refactoring of $\Pdata(z)$. The main reason why linear superposition is not correct is because the operator $u_t\mapsto \pd t p_t = -\nabla \cdot (u_tp_t)$ which maps $u_t$ to the distribution it effects **has additional dependence upon $p_t$**, which **depends nontrivially upon $x$**. Switching from conditional to marginal, we have $p_t(x \mid z)\mapsto p_t(x)=\int p_t(x\mid z)\Pdata(z)\, dz$; this introduces nontrivial $x$-dependence inside the divergence operator. 
</details>

<span style="color:green">
Alternative explanation:
</span> the marginal velocity at a point is the average over all conditional velocities, so $u_t(x) = \Exp_{z}[u_t(x\mid z) \mid X=x]$. It's critical to recognize here that the ensembling and conditioning is done w.r.t. the joint $p_t(x, z)$. 

:::{.proposition name="marginalization of score function"}
Given a distribution $p$, define its score function $\nabla \log p(x)$. The marginal score is connected to conditional score by 
\[
    \nabla \log p_t(x_t) = \int p_t(z\mid x_t) \nabla \log p_t(x_t\mid z)\, dz, \quad p_t(z\mid x_t) = \df{p_t(x\mid z)\Pdata(z)}{p_t(x)}
\] 
:::


## Optimization {#optimization -} 

Fixing $\Pdata$ and $p_t^\Target$, we can mathematically formulate $u_t^\Target$ using the continuity equation and marginalization trick. We parameterize $u_t^\theta$ in hopes of approximating $u_t^\Target$. This can be done by minimizing the (marginal) **flow matching loss**
\[ 
    \mca L_\FM(\theta) = \Exp_{t\sim \Unif, z\sim \Pdata, x\sim p_t(\cdot\mid z)} \left\|u_t^\theta(x) - u_t^\Target(x)\right\|^2 
\] 
The only problem being that $u_t^\Target$ is an intractable integral (sum for discrete datasets). A much more tractable quantity is the **conditional flow matching loss** which, upon drawing $z\sim \Pdata$, only asks the model to regress the conditional vector field for that $z$: 
\[ 
    \mca L_\CFM(\theta) = \Exp_{t\sim \Unif, z\sim \Pdata, x\sim p_t(\cdot\mid z)} \left\|u_t^\theta(x) - u_t^\Target(x\mid z)\right\|^2 
\] 
Similarly define the **score matching** and **conditional score matching** losses: 
\begin{aligned}
    \mca L_{\SM}(\theta) &= \Exp_{t\sim \Unif, x\sim p_t} \left\|\nabla \log p_t^\theta(x) - \nabla \log p_t^{\Target}(x)\right\|^2 \\
    \mca L_{\CSM}(\theta) &= \Exp_{t\sim \Unif, z\sim \Pdata, x\sim p_t(\cdot\mid z)} \left\|\nabla \log p_t^\theta(x) - \nabla \log p_t^{\Target}(x\mid z)\right\|^2
\end{aligned}

:::{.theorem #opEq name="optimization equivalence"}
$\nabla_\theta \mca L_\FM(\theta) = \nabla_\theta \mca L_\CFM(\theta)$. Similarly, $\nabla_\theta \mca L_\SM(\theta) = \nabla_\theta \mca L_\CSM(\theta)$. 
:::

<details>
<summary>Direct substitution</summary>
Expanding the squared norm for both losses, it suffices to show that 
\[ 
    \Exp[u_t^\theta(x)^T u_t^\Target(x)]
    = \Exp[u_t^\theta(x)^T u_t^\Target(x\mid z)]
\] 
Expand integrals and apply the marginalization equation \@ref(thm:margTrick):
\begin{aligned}
    \Exp_{t, x\sim p_t}[u_t^\theta(x)^T u_t^\Target(x)] 
    &= \iint p_t(x) u_t^\theta(x)^T \left[u_t^\Target(x)\right] \, dx \, dt  \\ 
    &= \iint p_t(x) u_t^\theta(x)^T \int u_t^*(x\mid z) p_t(z\mid x)\, dz \, dx \, dt \\ 
    &= \iiint u_t^\theta(x)^T u_t^*(x\mid z) p_t(x, z)\, dz\, dx\, dt \\ 
    &= \Exp_{t, z\sim \Pdata, x\sim p_t(\cdot\mid z)} [u_t^\theta(x)^T u_t^*(x\mid z)]
\end{aligned}
</details>

## Gaussian example {#gaussian -}

The next order of business is to work out a concrete example; this is almost the only example we'll ever need to work out. We begin by specifying an almost trivial conditional probability path: 

:::{.definition #condGaussianPath name="conditional Gaussian probability path"}
Consider a single point $z\in \R^d$, the following **Gaussian probability path** continuously collapses $\Pinit$ to $\delta_z$: 
\[ 
    p_t^\Target(x\mid z) = \mca N(x; \alpha_t z, \beta_t^2 I_d) 
    = \df 1 {(2\pi \beta_t^2)^{d/2}} \exp \left(-\df{\|x-\alpha_t z\|^2}{2\beta_t^2}\right)
\] 
where $\alpha_t, \beta_t$ are **noise schedulers** satisfying $\alpha_0=\beta_1=0$ and $\alpha_1=\beta_0=1$. Note that $x, z\in \R^d$. Fixing $z$, note that $p_t$ is the pushforward measure of $\Pinit$ under the flow 
\[ 
    \psi_t^\Target(x\mid z) = \alpha_t z + \beta_t x 
\] 
:::

:::{.proposition #gaussianCVFS name="Gaussian conditional vector field and score"}
Given $\alpha_t, \beta_t$, the following vector field realizes the conditional Gaussian probability path: 
\[ 
    u_t^\Target(x\mid z) = \left(\dot \alpha_t - \df{\dot \beta_t}{\beta_t} \alpha_t\right) z + \df{\dot \beta_t}{\beta_t} x 
\] 
For the special linear-scheduler case $\alpha_t=t, \beta_t=1-t$, we obtain 
\[ 
    u_t(x\mid z) = \left(1 + \df{t}{1-t}\right) z - \df{1}{1-t} x = \df {z-x} {1-t}
\] 
The score function is 
\[ 
    \nabla \log p_t^\Target(x\mid z) = -\df{x - \alpha_t z}{\beta_t^2} 
\] 
:::

<details>
<summary><span style="color:blue">IMPORTANT proof: instead of directly verifying the continuity equation, given $p_t$ construct vector field by (1) constructing a flow $\psi_t(x_0)$ whose pushforward measure of $p_0$ is $p_t$, and (2) finding $u_t$ such that $\pd t \psi_t(x_0) = u_t(\psi_t(x_0))$</span></summary>
Drop the $\Target$ superscript to reduce clutter. Instead of doing the hairy calculation for $\pd t p_t$, we recall that $p_t$ is the pushforward of $p_0=\mca N(0, I_d)$ under $\psi_t$, so it suffices to show that 
\[ 
    \pd t \psi_t(x\mid z) = u_t(\psi_t(x\mid z)\mid z) 
\] 
Unpacking this a bit more: fixing $z$ throughout, the map $x\mapsto \psi_t(x\mid z)$ sends initial $x\sim \Pinit$ to where it would be at time $t$ such that $x_t=\psi_t(x_0\mid z)\sim p_t$ for all $t$. Also recall that given flow $x_0\mapsto \Phi_t(x_0)$, the vector field generator of the flow $u_t$ satisfies 
\[ 
    \pd t \Phi_t(x_0) = \psi_t(x_t) = \psi_t(\Phi_t(x_0))
\] 
Returning to our original equation, we have 
\begin{aligned}
    u_t(\psi_t(x\mid z)\mid z)
        &= \left(
            \dot \alpha_t - \df{\dot \beta_t}{\beta_t} \alpha_t 
        \right) z + \df{\dot \beta_t}{\beta_t} (\alpha_t z + \beta_t x) \\ 
        &= \dot \alpha_t z + \dot \beta_t x = \pd t \psi_t 
\end{aligned}
</details>

- Again, there are many vector fields which can realize the Gaussian conditional probability path. This gauge freedom is embedded in our choice of $\psi_t$: there are many flow maps which realize the same specified pushforward measure. 

:::{.proposition #gaussianFormulae name="flow and score matching for Gaussian paths"}
Applying \@ref(prp:gaussianCVFS), we obtain the losses which make training protocol self-evident: 
\begin{aligned}
    \mca L_\CFM(\theta)
    &= \Exp_{t\sim \Unif, z\sim \Pdata, x\sim \mca N(\alpha_tz, \beta_t^2I_d)} \left\|
        u_t^\theta(x) - \left(\dot \alpha(t) - \df{\dot \beta_t}{\beta_t} \alpha_t \right)z 
        - \df{\dot \beta_t}{\beta_t} x 
    \right\|^2 \\ 
    &= \Exp_{t\sim \Unif, z\sim \Pdata, \epsilon \sim \mca N(0, I_d)} \left\|
        u_t^\theta(\alpha_t z + \beta_t \epsilon) + (\dot \alpha_t z + \dot \beta_t \epsilon) 
    \right\|
\end{aligned}
For simple linear interpolation, this instantiates to $\mca L_\CFM(\theta) = \Exp \|u_t^\theta(tz + \bar t\epsilon) - (z-\epsilon)^2\|^2$. In terms of score, we obtain 
\begin{aligned}
    \mca L_\CSM(\theta)
    &= \Exp_{t\sim \Unif, z\sim \Pdata, x\sim p_t(\cdot\mid z)} \left\|
        s_t^\theta(x) + \df{x - \alpha_tz}{\beta_t^2}
    \right\| \\ 
    &= \Exp_{t\sim \Unif, z\sim \Pdata, \epsilon \sim \mca N(0, I_d)} \left\|
       s_t^\theta(\alpha_t z + \beta_t\epsilon) + \df{\epsilon}{\beta_t}
    \right\|^2
\end{aligned}
The score network essentially tries to learn the noise $\epsilon$ which used to corrupt data. To avoid $\beta\to 0$ instability, Denoising Diffusion Probabilistic Models (DDPM) proposed to drop $1/\beta$ coefficient and predict $\epsilon_t^\theta$. Some algebra further shows that predicting the score is equivalent to predicting the target vector field: 
\[ 
    u_t^\Target(x\mid z) = \left(\beta_t^2 \df{\dot \alpha_t}{\alpha_t} - \dot \beta_t \beta_t\right) \nabla \log p_t(x\mid z) + \df{\dot \alpha_t}{\alpha_t} x 
\] 
Since both quantities share marginalization formula, the same equivalence holds for marginal targets. 
:::